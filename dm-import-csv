#!/usr/bin/env python2.7
# -*- coding: utf-8 -*-

import getopt
import json
import os
import sys

from hecatoncheir import CSVUtils
from hecatoncheir import DbProfilerRepository
from hecatoncheir import db
from hecatoncheir import logger as log
from hecatoncheir.businessglossary import GlossaryTerm
from hecatoncheir.msgutil import gettext as _
from hecatoncheir.repository import Repository
from hecatoncheir.schema import Schema2
from hecatoncheir.table import Table2
from hecatoncheir.tag import Tag2
from hecatoncheir.validation import ValidationRule

table_csv_keys = [
    'DATABASE_NAME',
    'SCHEMA_NAME',
    'TABLE_NAME']

table_csv_attrs = [
    'TABLE_NAME_NLS',
    'TABLE_COMMENT',
    'TAGS',
    'TABLE_OWNER']

column_csv_keys = [
    'DATABASE_NAME',
    'SCHEMA_NAME',
    'TABLE_NAME',
    'COLUMN_NAME']

column_csv_attrs = [
    'COLUMN_NAME_NLS',
    'COLUMN_COMMENT',
    'FK']

glossary_csv_keys = [
    'TERM',
    'DESCRIPTION_SHORT',
    'DESCRIPTION_LONG',
    'OWNER'
]

glossary_csv_attrs = [
    'CATEGORIES',
    'SYNONYMS',
    'RELATED_TERMS',
    'RELATED_ASSETS'
]

validation_csv_keys = [
    'DATABASE_NAME',
    'SCHEMA_NAME',
    'TABLE_NAME',
    'COLUMN_NAME',
    'DESCRIPTION',
    'RULE',
    'PARAM',
    'PARAM2'
]

validation_csv_attrs = [
]

schema_comment_csv_keys = [
    'DATABASE_NAME',
    'SCHEMA_NAME',
    'SCHEMA_DESCRIPTION',
    'SCHEMA_COMMENT'
]

schema_comment_csv_attrs = [
]

tag_comment_csv_keys = [
    'TAG_NAME',
    'TAG_DESCRIPTION',
    'TAG_COMMENT'
]

tag_comment_csv_attrs = [
]

csv_confs = [('validation', validation_csv_keys, validation_csv_attrs),
             ('column', column_csv_keys, column_csv_attrs),
             ('table', table_csv_keys, table_csv_attrs),
             ('glossary', glossary_csv_keys, glossary_csv_attrs),
             ('schemacomment', schema_comment_csv_keys,
              schema_comment_csv_attrs),
             ('tagcomment', tag_comment_csv_keys, tag_comment_csv_attrs)]


def usage():
    print '''
Usage: %s [repo file] [csv file]

Options:
    -E, --encoding=STRING      Encoding of the CSV file (default: sjis)
    --help                     Print this help.

''' % os.path.basename(sys.argv[0])

file_enc = 'sjis'


def open_csv_file(filename, csv_keys):
    reader = None
    try:
        reader = CSVUtils.CSVReader(filename)
        if reader.check_header(csv_keys) is False:
            return None
    except Exception as e:
        log.error(_("Could not open csv file `%s'.") % csv_file,
                  detail=unicode(e))
        sys.exit(1)
    return reader


def process_table_csv(repo, r):
    if not (r['database_name'] and r['schema_name'] and r['table_name']):
        msg = (_("Database name `%s' or table name `%s.%s' is not correct. "
                 "Skipping.") %
               (r['database_name'], r['schema_name'], r['table_name']))
        log.warning(msg)
        return 0

    t = Table2.find(r['database_name'], r['schema_name'],
                      r['table_name'])
    if len(t) == 0:
        tmp = (_("Table %s.%s.%s not found in the repository. "
                 "Skipping.") %
               (r['database_name'], r['schema_name'], r['table_name']))
        log.warning(tmp)
        return 0
    tab = t[0].data

    # update if a key exist, otherwise keep the old value.
    tab["table_name_nls"] = r.get('table_name_nls',
                                  tab.get("table_name_nls", ''))
    tab["comment"] = r.get('table_comment', tab.get("comment", ''))
    tab["owner"] = r.get('table_owner', tab.get("owner", ''))
    tab["tags"] = [x.strip() for x in r.get('tags', '').split(',')]

    tab.update()
    return 1


def process_column_csv(repo, r):
    if not (r['database_name'] and r['schema_name'] and r['table_name']):
        msg = (_("Database name `%s' or table name `%s.%s' is not correct. "
                 "Skipping.") %
               (r['database_name'], r['schema_name'], r['table_name']))
        log.warning(msg)
        return 0

    t = Table2.find(r['database_name'], r['schema_name'],
                    r['table_name'])
    if len(t) == 0:
        tmp = (_("Table %s.%s.%s not found in the repository. "
                 "Skipping.") %
               (r['database_name'], r['schema_name'], r['table_name']))
        log.warning(tmp)
        return 0
    tab = t[0].data

    for col in tab["columns"]:
        if col["column_name"] != r['column_name']:
            continue

        # update if a key exist, otherwise keep the old value.
        col["column_name_nls"] = r.get('column_name_nls',
                                       col.get("column_name_nls", ''))
        col["comment"] = r.get('column_comment',
                               col.get("comment", ''))
        if not r.get('fk'):
            continue
        for fk in [x.strip() for x in r['fk'].split(',')]:
            guess = True if fk[0] == '?' else False
            tmp = fk[1:].split('.') if guess else fk.split('.')
            # [table, column]
            #  -> [schema, table, column]
            if len(tmp) == 2:
                tmp.insert(0, tab["schema_name"])
            # [schema, table, column]
            #  -> [database, schema, table, column]
            if len(tmp) == 3:
                tmp.insert(0, tab["database_name"])
                tmp2 = [tab["database_name"], tab["schema_name"],
                        tab["table_name"], col["column_name"]]
                fk_list.append(tmp2 + tmp + [guess])
    tab.update()
    return 1


def process_glossary_csv(repo, r):
    if len(r['term']) == 0:
        return 0
    t = GlossaryTerm.create(r['term'],
                            r['description_short'],
                            r['description_long'],
                            r['owner'],
                            [x.strip() for x in r.get('categories', '')
                             .split(',')],
                            [x.strip() for x in r.get('synonyms', '')
                             .split(',')],
                            [x.strip() for x in r.get('related_terms', '')
                             .split(',')],
                            [x.strip() for x in r.get('related_assets', '')
                             .split(',')])
    assert isinstance(t, GlossaryTerm)
    return 1


def process_validation_csv(repo, r):
    try:
        ValidationRule.create(r['database_name'], r['schema_name'],
                              r['table_name'], r['column_name'],
                              r['description'], r['rule'],
                              r['param'], r['param2'])
    except Exception as ex:
        log.error(_('Could not import a vaidation rule: %s') % str(r), detail=str(ex))
        return 0
    return 1


def process_schemacomment_csv(repo, r):
    # Creating first, and if an integrity error occures, update next.
    try:
        Schema2.create(r['database_name'], r['schema_name'],
                       r['schema_description'], r['schema_comment'])
    except Exception as ex:
        if not unicode(ex).startswith('(sqlite3.IntegrityError) columns database_name, schema_name are not unique'):
            raise ex

    s = Schema2.find(r['database_name'], r['schema_name'])
    if s:
        s.description = r['schema_description']
        s.comment = r['schema_comment']
        s.update()
    else:
        log.warning("Schema `%s.%s' not found." % (r['database_name'], r['schema_name']))
        return 0
    return 1


def process_tagcomment_csv(repo, r):
    try:
        Tag2.create(r['tag_name'], r['tag_description'], r['tag_comment'])
    except Exception as ex:
        if not unicode(ex).startswith('(sqlite3.IntegrityError) column label is not unique'):
            raise ex

    t = Tag2.find(r['tag_name'])
    if t:
        t.description = r['tag_description']
        t.comment = r['tag_comment']
        t.update()
    else:
        log.warning("Tag `%s' not found." % (r['tag_name']))
        return 0
    return 1


if __name__ == "__main__":
    try:
        opts, args = getopt.getopt(sys.argv[1:], "E:",
                                   ["encoding=", "help", "debug"])
    except getopt.GetoptError as err:
        log.error(unicode(err))
        usage()
        sys.exit(1)

    for o, a in opts:
        if o in ("--debug"):
            log.debug_enabled = True
        elif o in ("-E"):
            file_enc = a
        elif o in ("--encoding"):
            file_enc = a
        elif o in ("--help"):
            usage()
            sys.exit(0)
        else:
            log.error("unexpected option. internal error.")
            sys.exit(1)

    if len(args) < 2:
        usage()
        sys.exit(1)

    input_file = args[0]
    csv_file = args[1]

    log.info(_("Importing csv file `%s' into the repository `%s'.") %
             (csv_file, input_file))

    # detect csv format and prepare the csv reader.
    reader = None
    format = None
    for (f, k, a) in csv_confs:
        reader = open_csv_file(csv_file, k)
        if reader:
            header = k + a
            format = f
            break
    if reader is None:
        log.error(_("Unsupported csv format."))
        sys.exit(1)
    log.info(_("CSV format: %s") % format)
    log.trace("reader.header: %s" % reader.header)

    repo = DbProfilerRepository.DbProfilerRepository(input_file)
    repo.init()
    repo.open()

    db.creds = {}
    db.creds['use_sqlite'] = True
    db.creds['dbname'] = input_file
    repo2 = Repository()

    lines = 0
    merged = 0
    fk_list = []
    for r in reader.readline_as_dict(use_lower=True):
        lines += 1
        if format == 'table':
            merged += process_table_csv(repo, r)
        elif format == 'column':
            merged += process_column_csv(repo, r)
        elif format == 'glossary':
            merged += process_glossary_csv(repo, r)
        elif format == 'validation':
            merged += process_validation_csv(repo, r)
        elif format == 'schemacomment':
            merged += process_schemacomment_csv(repo, r)
        elif format == 'tagcomment':
            merged += process_tagcomment_csv(repo, r)
        else:
            log.error("Unreachable code.")
            sys.exit(1)

    for fk in fk_list:
        repo.remove_table_fk(fk[0], fk[1], fk[2], fk[3], fk[4], fk[5], fk[6],
                             fk[7])
        repo.put_table_fk(fk[0], fk[1], fk[2], fk[3], fk[4], fk[5], fk[6],
                          fk[7], fk[8])
    repo.close()
    log.info(_("%d records successfully imported into the repository.") %
             merged)

    sys.exit(0)
